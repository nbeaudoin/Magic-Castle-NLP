{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/11/2019</td>\n",
       "      <td>So this place gets a lot of love, and a bit of...</td>\n",
       "      <td>4 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/1/2020</td>\n",
       "      <td>this was my favorite place to visit by far oth...</td>\n",
       "      <td>5 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/9/2020</td>\n",
       "      <td>The Magic Castle (Hollywood, CA)I had this pla...</td>\n",
       "      <td>4 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/23/2020</td>\n",
       "      <td>I recently had the pleasure of visiting the Ma...</td>\n",
       "      <td>4 star rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7/22/2019</td>\n",
       "      <td>So i learned a couple more new things througho...</td>\n",
       "      <td>5 star rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                                             Review         Rating\n",
       "0  9/11/2019  So this place gets a lot of love, and a bit of...  4 star rating\n",
       "1  11/1/2020  this was my favorite place to visit by far oth...  5 star rating\n",
       "2   2/9/2020  The Magic Castle (Hollywood, CA)I had this pla...  4 star rating\n",
       "3  1/23/2020  I recently had the pleasure of visiting the Ma...  4 star rating\n",
       "4  7/22/2019  So i learned a couple more new things througho...  5 star rating"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Magic_Castle_Reviews.csv', index_col=\"Unnamed: 0\").reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df.Review.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['so', 'this', 'place', 'gets', 'lot', 'of', 'love', 'and', 'bit', 'of', 'hate', 'too', 'didn', 'love', 'it', 'but', 'definitely', 'didn', 'hate', 'it', 'it', 'an', 'interesting', 'place', 'for', 'sure', 'the', 'building', 'itself', 'is', 'gorgeous', 'it', 'beautiful', 'on', 'the', 'outside', 'and', 'spectacular', 'on', 'the', 'inside', 'pretty', 'sure', 'read', 'that', 'the', 'building', 'itself', 'is', 'over', 'years', 'old', 'the', 'business', 'inside', 'the', 'magic', 'castle', 'has', 'been', 'operating', 'for', 'decades', 'know', 'they', 'call', 'themselves', 'private', 'club', 'and', 'you', 'have', 'to', 'be', 'invited', 'to', 'get', 'in', 'or', 'stay', 'at', 'the', 'magic', 'castle', 'hotel', 'next', 'door', 'like', 'we', 'did', 'but', 'personally', 'find', 'the', 'admissions', 'policy', 'bit', 'obnoxious', 'it', 'certainly', 'didn', 'feel', 'like', 'private', 'club', 'but', 'it', 'is', 'what', 'it', 'is', 'everyone', 'has', 'tips', 'on', 'how', 'to', 'get', 'an', 'invitation', 'got', 'nothing', 'for', 'you', 'on', 'that', 'one', 'folks', 'yes', 'it', 'expensive', 'everyone', 'gets', 'charged', 'an', 'admission', 'fee', 'let', 'just', 'call', 'that', 'your', 'show', 'price', 'everyone', 'is', 'also', 'forced', 'to', 'pay', 'for', 'either', 'brunch', 'on', 'the', 'weekends', 'or', 'dinner', 'it', 'all', 'you', 'can', 'eat', 'for', 'brunch', 'but', 'it', 'pricey', 'pretty', 'much', 'like', 'any', 'brunch', 'is', 'it', 'worth', 'it', 'probably', 'not', 'but', 'you', 'gotta', 'pay', 'to', 'play', 'overall', 'you', 'will', 'probably', 'be', 'there', 'for', 'or', 'so', 'hours', 'that', 'very', 'long', 'time', 'for', 'any', 'experience', 'so', 'do', 'the', 'math', 'and', 'decide', 'if', 'you', 'received', 'value', 'for', 'your', 'dollar', 'feel', 'like', 'we', 'received', 'value', 'now', 'they', 'give', 'you', 'little', 'pitch', 'at', 'the', 'start', 'about', 'how', 'you', 'are', 'guaranteed', 'to', 'see', 'only', 'one', 'show', 'and', 'any', 'extra', 'shows', 'you', 'see', 'would', 'be', 'bonus', 'oh', 'thank', 'you', 'sir', 'so', 'much', 'sure', 'hope', 'the', 'lord', 'is', 'smiling', 'on', 'me', 'today', 'so', 'can', 'get', 'to', 'see', 'those', 'bonus', 'shows', 'personally', 'really', 'think', 'this', 'little', 'marketing', 'pitch', 'and', 'lowering', 'of', 'expectations', 'so', 'that', 'after', 'you', 'see', 'all', 'the', 'shows', 'you', 'feel', 'like', 'you', 'received', 'something', 'extra', 'or', 'something', 'special', 'you', 'received', 'bonus', 'right', 'we', 'went', 'for', 'the', 'brunch', 'because', 'that', 'the', 'only', 'time', 'you', 'can', 'bring', 'kids', 'the', 'food', 'was', 'pretty', 'darn', 'good', 'and', 'bottomless', 'mimosas', 'are', 'included', 'there', 'endless', 'shrimp', 'lox', 'crab', 'legs', 'roast', 'beef', 'salads', 'bacon', 'sausage', 'and', 'an', 'omelet', 'station', 'among', 'other', 'things', 'liked', 'pretty', 'much', 'all', 'of', 'it', 'what', 'didn', 'like', 'is', 'that', 'the', 'food', 'is', 'served', 'in', 'ridiculously', 'small', 'space', 'know', 'the', 'building', 'is', 'very', 'old', 'and', 'they', 'are', 'constrained', 'by', 'space', 'limitations', 'but', 'they', 'still', 'could', 'enlarge', 'the', 'food', 'area', 'however', 'if', 'they', 'did', 'they', 'would', 'then', 'lose', 'some', 'tables', 'and', 'thus', 'some', 'customers', 'so', 'they', 'choose', 'to', 'sardine', 'you', 'and', 'the', 'food', 'into', 'little', 'closet', 'sized', 'spot', 'others', 'have', 'noted', 'that', 'they', 'felt', 'rushed', 'by', 'their', 'servers', 'we', 'weren', 'rushed', 'but', 'there', 'definitely', 'was', 'some', 'strong', 'encouragement', 'given', 'to', 'us', 'and', 'others', 'that', 'if', 'we', 'finished', 'up', 'by', 'certain', 'time', 'we', 'could', 'make', 'it', 'in', 'time', 'to', 'see', 'one', 'of', 'those', 'special', 'bonus', 'shows', 'some', 'people', 'hurried', 'up', 'their', 'brunch', 'and', 'left', 'for', 'the', 'shows', 'and', 'others', 'didn', 'believe', 'you', 'can', 'enjoy', 'your', 'food', 'and', 'not', 'rush', 'and', 'still', 'make', 'those', 'shows', 'at', 'some', 'point', 'the', 'guaranteed', 'show', 'was', 'very', 'good', 'the', 'smaller', 'shows', 'were', 'fun', 'but', 'got', 'little', 'tired', 'of', 'all', 'the', 'card', 'tricks', 'all', 'of', 'the', 'kiddos', 'seemed', 'to', 'love', 'all', 'the', 'shows', 'so', 'if', 'you', 're', 'bringing', 'kids', 'they', 'll', 'probably', 'really', 'enjoy', 'the', 'experience', 'invisible', 'irma', 'the', 'player', 'piano', 'is', 'must', 'see', 'must', 'do', 'her', 'knowledge', 'of', 'songs', 'was', 'excellent', 'you', 've', 'got', 'to', 'check', 'it', 'out', 'the', 'bars', 'throughout', 'the', 'building', 'were', 'stunningly', 'beautiful', 'didn', 'frequent', 'any', 'of', 'them', 'but', 'they', 'were', 'gorgeous', 'there', 'an', 'old', 'pay', 'phone', 'inside', 'one', 'of', 'the', 'men', 'rooms', 'it', 'plays', 'alibis', 'or', 'excuses', 'if', 'you', 're', 'calling', 'someone', 'and', 'want', 'to', 'disguise', 'your', 'true', 'location', 'it', 'pretty', 'cute', 'if', 'you', 'can', 'go', 'into', 'this', 'men', 'room', 'you', 'should', 'check', 'it', 'out', 'followed', 'the', 'strict', 'no', 'photos', 'policy', 'so', 'other', 'than', 'the', 'exterior', 'and', 'the', 'lobby', 'where', 'taking', 'photos', 'are', 'allowed', 'didn', 'take', 'any', 'pictures', 'they', 'are', 'very', 'serious', 'about', 'this', 'rule', 'although', 'not', 'sure', 'why', 'would', 'come', 'back', 'maybe', 'would', 'go', 'often', 'no', 'was', 'there', 'value', 'received', 'yes', 'was', 'it', 'an', 'amazing', 'value', 'no', 'wouldn', 'say', 'that', 'all', 'said', 'glad', 'we', 'went', 'and', 'my', 'kid', 'had', 'great', 'time']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.phrases.Phraser at 0x7fc6b441a668>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so',\n",
       " 'this',\n",
       " 'place',\n",
       " 'gets',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'love',\n",
       " 'and',\n",
       " 'bit',\n",
       " 'of',\n",
       " 'hate',\n",
       " 'too',\n",
       " 'didn',\n",
       " 'love',\n",
       " 'it',\n",
       " 'but',\n",
       " 'definitely',\n",
       " 'didn',\n",
       " 'hate',\n",
       " 'it',\n",
       " 'it',\n",
       " 'an',\n",
       " 'interesting',\n",
       " 'place',\n",
       " 'for',\n",
       " 'sure',\n",
       " 'the',\n",
       " 'building',\n",
       " 'itself',\n",
       " 'is',\n",
       " 'gorgeous',\n",
       " 'it',\n",
       " 'beautiful',\n",
       " 'on',\n",
       " 'the',\n",
       " 'outside',\n",
       " 'and',\n",
       " 'spectacular',\n",
       " 'on',\n",
       " 'the',\n",
       " 'inside',\n",
       " 'pretty',\n",
       " 'sure',\n",
       " 'read',\n",
       " 'that',\n",
       " 'the',\n",
       " 'building',\n",
       " 'itself',\n",
       " 'is',\n",
       " 'over',\n",
       " 'years',\n",
       " 'old',\n",
       " 'the',\n",
       " 'business',\n",
       " 'inside',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'castle',\n",
       " 'has',\n",
       " 'been',\n",
       " 'operating',\n",
       " 'for',\n",
       " 'decades',\n",
       " 'know',\n",
       " 'they',\n",
       " 'call',\n",
       " 'themselves',\n",
       " 'private_club',\n",
       " 'and',\n",
       " 'you',\n",
       " 'have',\n",
       " 'to',\n",
       " 'be',\n",
       " 'invited',\n",
       " 'to',\n",
       " 'get',\n",
       " 'in',\n",
       " 'or',\n",
       " 'stay',\n",
       " 'at',\n",
       " 'the',\n",
       " 'magic',\n",
       " 'castle',\n",
       " 'hotel',\n",
       " 'next',\n",
       " 'door',\n",
       " 'like',\n",
       " 'we',\n",
       " 'did',\n",
       " 'but',\n",
       " 'personally',\n",
       " 'find',\n",
       " 'the',\n",
       " 'admissions',\n",
       " 'policy',\n",
       " 'bit',\n",
       " 'obnoxious',\n",
       " 'it',\n",
       " 'certainly',\n",
       " 'didn',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'private_club',\n",
       " 'but',\n",
       " 'it',\n",
       " 'is',\n",
       " 'what',\n",
       " 'it',\n",
       " 'is',\n",
       " 'everyone',\n",
       " 'has',\n",
       " 'tips',\n",
       " 'on',\n",
       " 'how',\n",
       " 'to',\n",
       " 'get',\n",
       " 'an',\n",
       " 'invitation',\n",
       " 'got',\n",
       " 'nothing',\n",
       " 'for',\n",
       " 'you',\n",
       " 'on',\n",
       " 'that',\n",
       " 'one',\n",
       " 'folks',\n",
       " 'yes',\n",
       " 'it',\n",
       " 'expensive',\n",
       " 'everyone',\n",
       " 'gets',\n",
       " 'charged',\n",
       " 'an',\n",
       " 'admission',\n",
       " 'fee',\n",
       " 'let',\n",
       " 'just',\n",
       " 'call',\n",
       " 'that',\n",
       " 'your',\n",
       " 'show',\n",
       " 'price',\n",
       " 'everyone',\n",
       " 'is',\n",
       " 'also',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'pay',\n",
       " 'for',\n",
       " 'either',\n",
       " 'brunch',\n",
       " 'on',\n",
       " 'the',\n",
       " 'weekends',\n",
       " 'or',\n",
       " 'dinner',\n",
       " 'it',\n",
       " 'all',\n",
       " 'you',\n",
       " 'can',\n",
       " 'eat',\n",
       " 'for',\n",
       " 'brunch',\n",
       " 'but',\n",
       " 'it',\n",
       " 'pricey',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'like',\n",
       " 'any',\n",
       " 'brunch',\n",
       " 'is',\n",
       " 'it',\n",
       " 'worth',\n",
       " 'it',\n",
       " 'probably',\n",
       " 'not',\n",
       " 'but',\n",
       " 'you',\n",
       " 'gotta',\n",
       " 'pay',\n",
       " 'to',\n",
       " 'play',\n",
       " 'overall',\n",
       " 'you',\n",
       " 'will',\n",
       " 'probably',\n",
       " 'be',\n",
       " 'there',\n",
       " 'for',\n",
       " 'or',\n",
       " 'so',\n",
       " 'hours',\n",
       " 'that',\n",
       " 'very',\n",
       " 'long',\n",
       " 'time',\n",
       " 'for',\n",
       " 'any',\n",
       " 'experience',\n",
       " 'so',\n",
       " 'do',\n",
       " 'the',\n",
       " 'math',\n",
       " 'and',\n",
       " 'decide',\n",
       " 'if',\n",
       " 'you',\n",
       " 'received',\n",
       " 'value',\n",
       " 'for',\n",
       " 'your',\n",
       " 'dollar',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'we',\n",
       " 'received',\n",
       " 'value',\n",
       " 'now',\n",
       " 'they',\n",
       " 'give',\n",
       " 'you',\n",
       " 'little',\n",
       " 'pitch',\n",
       " 'at',\n",
       " 'the',\n",
       " 'start',\n",
       " 'about',\n",
       " 'how',\n",
       " 'you',\n",
       " 'are',\n",
       " 'guaranteed',\n",
       " 'to',\n",
       " 'see',\n",
       " 'only',\n",
       " 'one',\n",
       " 'show',\n",
       " 'and',\n",
       " 'any',\n",
       " 'extra',\n",
       " 'shows',\n",
       " 'you',\n",
       " 'see',\n",
       " 'would',\n",
       " 'be',\n",
       " 'bonus',\n",
       " 'oh',\n",
       " 'thank',\n",
       " 'you',\n",
       " 'sir',\n",
       " 'so',\n",
       " 'much',\n",
       " 'sure',\n",
       " 'hope',\n",
       " 'the',\n",
       " 'lord',\n",
       " 'is',\n",
       " 'smiling',\n",
       " 'on',\n",
       " 'me',\n",
       " 'today',\n",
       " 'so',\n",
       " 'can',\n",
       " 'get',\n",
       " 'to',\n",
       " 'see',\n",
       " 'those',\n",
       " 'bonus',\n",
       " 'shows',\n",
       " 'personally',\n",
       " 'really',\n",
       " 'think',\n",
       " 'this',\n",
       " 'little',\n",
       " 'marketing',\n",
       " 'pitch',\n",
       " 'and',\n",
       " 'lowering',\n",
       " 'of',\n",
       " 'expectations',\n",
       " 'so',\n",
       " 'that',\n",
       " 'after',\n",
       " 'you',\n",
       " 'see',\n",
       " 'all',\n",
       " 'the',\n",
       " 'shows',\n",
       " 'you',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'you',\n",
       " 'received',\n",
       " 'something',\n",
       " 'extra',\n",
       " 'or',\n",
       " 'something',\n",
       " 'special',\n",
       " 'you',\n",
       " 'received',\n",
       " 'bonus',\n",
       " 'right',\n",
       " 'we',\n",
       " 'went',\n",
       " 'for',\n",
       " 'the',\n",
       " 'brunch',\n",
       " 'because',\n",
       " 'that',\n",
       " 'the',\n",
       " 'only',\n",
       " 'time',\n",
       " 'you',\n",
       " 'can',\n",
       " 'bring',\n",
       " 'kids',\n",
       " 'the',\n",
       " 'food',\n",
       " 'was',\n",
       " 'pretty',\n",
       " 'darn',\n",
       " 'good',\n",
       " 'and',\n",
       " 'bottomless_mimosas',\n",
       " 'are',\n",
       " 'included',\n",
       " 'there',\n",
       " 'endless',\n",
       " 'shrimp',\n",
       " 'lox',\n",
       " 'crab_legs',\n",
       " 'roast',\n",
       " 'beef',\n",
       " 'salads',\n",
       " 'bacon_sausage',\n",
       " 'and',\n",
       " 'an',\n",
       " 'omelet',\n",
       " 'station',\n",
       " 'among',\n",
       " 'other',\n",
       " 'things',\n",
       " 'liked',\n",
       " 'pretty',\n",
       " 'much',\n",
       " 'all',\n",
       " 'of',\n",
       " 'it',\n",
       " 'what',\n",
       " 'didn',\n",
       " 'like',\n",
       " 'is',\n",
       " 'that',\n",
       " 'the',\n",
       " 'food',\n",
       " 'is',\n",
       " 'served',\n",
       " 'in',\n",
       " 'ridiculously',\n",
       " 'small',\n",
       " 'space',\n",
       " 'know',\n",
       " 'the',\n",
       " 'building',\n",
       " 'is',\n",
       " 'very',\n",
       " 'old',\n",
       " 'and',\n",
       " 'they',\n",
       " 'are',\n",
       " 'constrained',\n",
       " 'by',\n",
       " 'space',\n",
       " 'limitations',\n",
       " 'but',\n",
       " 'they',\n",
       " 'still',\n",
       " 'could',\n",
       " 'enlarge',\n",
       " 'the',\n",
       " 'food',\n",
       " 'area',\n",
       " 'however',\n",
       " 'if',\n",
       " 'they',\n",
       " 'did',\n",
       " 'they',\n",
       " 'would',\n",
       " 'then',\n",
       " 'lose',\n",
       " 'some',\n",
       " 'tables',\n",
       " 'and',\n",
       " 'thus',\n",
       " 'some',\n",
       " 'customers',\n",
       " 'so',\n",
       " 'they',\n",
       " 'choose',\n",
       " 'to',\n",
       " 'sardine',\n",
       " 'you',\n",
       " 'and',\n",
       " 'the',\n",
       " 'food',\n",
       " 'into',\n",
       " 'little',\n",
       " 'closet',\n",
       " 'sized',\n",
       " 'spot',\n",
       " 'others',\n",
       " 'have',\n",
       " 'noted',\n",
       " 'that',\n",
       " 'they',\n",
       " 'felt',\n",
       " 'rushed',\n",
       " 'by',\n",
       " 'their',\n",
       " 'servers',\n",
       " 'we',\n",
       " 'weren',\n",
       " 'rushed',\n",
       " 'but',\n",
       " 'there',\n",
       " 'definitely',\n",
       " 'was',\n",
       " 'some',\n",
       " 'strong',\n",
       " 'encouragement',\n",
       " 'given',\n",
       " 'to',\n",
       " 'us',\n",
       " 'and',\n",
       " 'others',\n",
       " 'that',\n",
       " 'if',\n",
       " 'we',\n",
       " 'finished',\n",
       " 'up',\n",
       " 'by',\n",
       " 'certain',\n",
       " 'time',\n",
       " 'we',\n",
       " 'could',\n",
       " 'make',\n",
       " 'it',\n",
       " 'in',\n",
       " 'time',\n",
       " 'to',\n",
       " 'see',\n",
       " 'one',\n",
       " 'of',\n",
       " 'those',\n",
       " 'special',\n",
       " 'bonus',\n",
       " 'shows',\n",
       " 'some',\n",
       " 'people',\n",
       " 'hurried',\n",
       " 'up',\n",
       " 'their',\n",
       " 'brunch',\n",
       " 'and',\n",
       " 'left',\n",
       " 'for',\n",
       " 'the',\n",
       " 'shows',\n",
       " 'and',\n",
       " 'others',\n",
       " 'didn',\n",
       " 'believe',\n",
       " 'you',\n",
       " 'can',\n",
       " 'enjoy',\n",
       " 'your',\n",
       " 'food',\n",
       " 'and',\n",
       " 'not',\n",
       " 'rush',\n",
       " 'and',\n",
       " 'still',\n",
       " 'make',\n",
       " 'those',\n",
       " 'shows',\n",
       " 'at',\n",
       " 'some',\n",
       " 'point',\n",
       " 'the',\n",
       " 'guaranteed',\n",
       " 'show',\n",
       " 'was',\n",
       " 'very',\n",
       " 'good',\n",
       " 'the',\n",
       " 'smaller',\n",
       " 'shows',\n",
       " 'were',\n",
       " 'fun',\n",
       " 'but',\n",
       " 'got',\n",
       " 'little',\n",
       " 'tired',\n",
       " 'of',\n",
       " 'all',\n",
       " 'the',\n",
       " 'card',\n",
       " 'tricks',\n",
       " 'all',\n",
       " 'of',\n",
       " 'the',\n",
       " 'kiddos',\n",
       " 'seemed',\n",
       " 'to',\n",
       " 'love',\n",
       " 'all',\n",
       " 'the',\n",
       " 'shows',\n",
       " 'so',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'bringing',\n",
       " 'kids',\n",
       " 'they',\n",
       " 'll',\n",
       " 'probably',\n",
       " 'really',\n",
       " 'enjoy',\n",
       " 'the',\n",
       " 'experience',\n",
       " 'invisible_irma',\n",
       " 'the',\n",
       " 'player_piano',\n",
       " 'is',\n",
       " 'must',\n",
       " 'see',\n",
       " 'must',\n",
       " 'do',\n",
       " 'her',\n",
       " 'knowledge',\n",
       " 'of',\n",
       " 'songs',\n",
       " 'was',\n",
       " 'excellent',\n",
       " 'you',\n",
       " 've',\n",
       " 'got',\n",
       " 'to',\n",
       " 'check',\n",
       " 'it',\n",
       " 'out',\n",
       " 'the',\n",
       " 'bars',\n",
       " 'throughout',\n",
       " 'the',\n",
       " 'building',\n",
       " 'were',\n",
       " 'stunningly',\n",
       " 'beautiful',\n",
       " 'didn',\n",
       " 'frequent',\n",
       " 'any',\n",
       " 'of',\n",
       " 'them',\n",
       " 'but',\n",
       " 'they',\n",
       " 'were',\n",
       " 'gorgeous',\n",
       " 'there',\n",
       " 'an',\n",
       " 'old',\n",
       " 'pay',\n",
       " 'phone',\n",
       " 'inside',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'men',\n",
       " 'rooms',\n",
       " 'it',\n",
       " 'plays',\n",
       " 'alibis',\n",
       " 'or',\n",
       " 'excuses',\n",
       " 'if',\n",
       " 'you',\n",
       " 're',\n",
       " 'calling',\n",
       " 'someone',\n",
       " 'and',\n",
       " 'want',\n",
       " 'to',\n",
       " 'disguise',\n",
       " 'your',\n",
       " 'true',\n",
       " 'location',\n",
       " 'it',\n",
       " 'pretty',\n",
       " 'cute',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'go',\n",
       " 'into',\n",
       " 'this',\n",
       " 'men',\n",
       " 'room',\n",
       " 'you',\n",
       " 'should',\n",
       " 'check',\n",
       " 'it',\n",
       " 'out',\n",
       " 'followed',\n",
       " 'the',\n",
       " 'strict',\n",
       " 'no',\n",
       " 'photos',\n",
       " 'policy',\n",
       " 'so',\n",
       " 'other',\n",
       " 'than',\n",
       " 'the',\n",
       " 'exterior',\n",
       " 'and',\n",
       " 'the',\n",
       " 'lobby',\n",
       " 'where',\n",
       " 'taking',\n",
       " 'photos',\n",
       " 'are',\n",
       " 'allowed',\n",
       " 'didn',\n",
       " 'take',\n",
       " 'any',\n",
       " 'pictures',\n",
       " 'they',\n",
       " 'are',\n",
       " 'very',\n",
       " 'serious',\n",
       " 'about',\n",
       " 'this',\n",
       " 'rule',\n",
       " 'although',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'why',\n",
       " 'would',\n",
       " 'come',\n",
       " 'back',\n",
       " 'maybe',\n",
       " 'would',\n",
       " 'go',\n",
       " 'often',\n",
       " 'no',\n",
       " 'was',\n",
       " 'there',\n",
       " 'value',\n",
       " 'received',\n",
       " 'yes',\n",
       " 'was',\n",
       " 'it',\n",
       " 'an',\n",
       " 'amazing',\n",
       " 'value',\n",
       " 'no',\n",
       " 'wouldn',\n",
       " 'say',\n",
       " 'that',\n",
       " 'all',\n",
       " 'said',\n",
       " 'glad',\n",
       " 'we',\n",
       " 'went',\n",
       " 'and',\n",
       " 'my',\n",
       " 'kid',\n",
       " 'had',\n",
       " 'great',\n",
       " 'time']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram[data_words[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the first word?\n",
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viz time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
